# ğŸ¥ videochat-withme

Real-time AI video chat skill for [OpenClaw](https://github.com/openclaw/openclaw). Talk face-to-face with your AI agent â€” it sees your camera, hears your voice, and responds with its own personality, memory, and voice.

https://github.com/user-attachments/assets/demo-placeholder

## âœ¨ Features

- **ğŸ¤ Voice conversation** â€” Groq Whisper for fast speech-to-text (~1s latency)
- **ğŸ“· Vision** â€” Your agent sees you via camera (base64 frames sent to LLM)
- **ğŸ”Š AI voice** â€” edge-tts for natural text-to-speech responses
- **ğŸ§  Full personality** â€” Routes through your OpenClaw agent (memory, personality, tools)
- **ğŸ“± Mobile support** â€” HTTPS with self-signed certs, works on phone browsers
- **ğŸ”’ Privacy-conscious** â€” No recordings stored; audio processed via Groq Whisper (cloud STT), TTS via Microsoft edge-tts (cloud). Camera frames sent to your OpenClaw gateway â†’ your LLM provider (âš ï¸ frames may reach cloud if using a cloud LLM)

## ğŸ—ï¸ Architecture

```
ğŸ¤ Voice â†’ Groq Whisper (STT)
ğŸ“· Camera â†’ base64 frame
    â†“
OpenClaw /v1/chat/completions â†’ Your Agent (personality + memory)
    â†“
edge-tts (TTS) â†’ ğŸ”Š Audio playback
```

## ğŸ” Data Flows & Privacy

| Data | Destination | Type |
|------|-------------|------|
| ğŸ¤ Audio recordings | `api.groq.com` (Groq Whisper) | â˜ï¸ Cloud STT |
| ğŸ”Š Text for speech | Microsoft edge-tts service | â˜ï¸ Cloud TTS |
| ğŸ“· Camera frames (base64) + text | `localhost` OpenClaw gateway â†’ **your configured LLM** | âš ï¸ Depends on LLM provider |
| ğŸ’¬ Conversation | Your configured LLM (via gateway) | âš ï¸ Depends on LLM provider |

> **âš ï¸ Important:** Camera frames are encoded as base64 and sent to your OpenClaw gateway's `/v1/chat/completions` endpoint. If your gateway forwards to a **cloud LLM** (e.g., Claude, GPT), those frames **will leave your machine**. If you want frames to stay local, configure your gateway to use a local/self-hosted model.

**What is NOT stored:**
- No recordings are saved to disk (beyond temporary `/tmp` files during processing)
- No conversation data is persisted on any server
- The API proxy is stateless

**Credentials accessed:**
- `GROQ_API_KEY` â€” for Whisper STT (from env var or `~/.openclaw/secrets/groq_api_key.txt`)
- OpenClaw gateway auth token â€” read from `~/.openclaw/openclaw.json` (required for chatCompletions API)

## ğŸ“‹ Prerequisites

- **macOS** (uses launchd for service management)
- **Python 3.10+**
- **ffmpeg** (`brew install ffmpeg`)
- **OpenClaw** running with `chatCompletions` enabled
- **Groq API key** (free at [console.groq.com](https://console.groq.com/keys))

### Enable chatCompletions in OpenClaw

Add to `~/.openclaw/openclaw.json`:

```json
{
  "gateway": {
    "http": {
      "endpoints": {
        "chatCompletions": { "enabled": true }
      }
    }
  }
}
```

Then restart OpenClaw.

## ğŸš€ Quick Start

### 1. Install as OpenClaw skill

```bash
# Clone into your skills directory
git clone https://github.com/sxu75374/videochat-withme.git ~/.openclaw/workspace/skills/videochat-withme
```

### 2. Run setup

```bash
cd ~/.openclaw/workspace/skills/videochat-withme
bash scripts/setup.sh
```

This interactive script handles everything:
- Installs Python dependencies (`fastapi`, `uvicorn`, `edge-tts`, `httpx`)
- Prompts for your Groq API key
- Generates SSL certificates (via [mkcert](https://github.com/FiloSottile/mkcert))
- Installs a `launchd` service for auto-start

### 3. Open in browser

Visit **https://localhost:8766** and allow camera/microphone access.

> ğŸ’¡ First visit will show a certificate warning â€” click "Advanced â†’ Continue" (self-signed cert).

## ğŸ“± Mobile Access

The server runs with HTTPS so mobile browsers can access camera/mic:

- **Same WiFi:** `https://<your-local-ip>:8766`
- **Any network (via Tailscale):** `https://<tailscale-ip>:8766`

## ğŸ¤– Agent Integration

Your OpenClaw agent can start calls automatically. See [SKILL.md](./SKILL.md) for agent instructions.

**Quick example** â€” when user says "video chat":
```bash
# Check if service is running
curl -sk https://localhost:8766/api/config

# Pop up incoming call notification (macOS)
bash scripts/call.sh
```

## ğŸ“ Project Structure

```
videochat-withme/
â”œâ”€â”€ SKILL.md              # OpenClaw skill definition + agent instructions
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh          # One-time setup (deps, certs, launchd)
â”‚   â”œâ”€â”€ server.py         # FastAPI server (STT, TTS, video, chat)
â”‚   â”œâ”€â”€ call.sh           # Trigger incoming call notification
â”‚   â”œâ”€â”€ start.sh          # Start service
â”‚   â””â”€â”€ stop.sh           # Stop service
â””â”€â”€ assets/
    â””â”€â”€ index.html         # Video chat UI (split-screen, push-to-talk)
```

## âš™ï¸ Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `GROQ_API_KEY` | `~/.openclaw/secrets/groq_api_key.txt` | Groq API key for Whisper STT |
| `PORT` | `8766` | Server port |
| `AGENT_NAME` | `AI Assistant` | Display name for the agent |
| `USER_NAME` | `User` | Display name for the user |
| `SSL_CERT` / `SSL_KEY` | Auto-detected | SSL certificate paths |

## ğŸ› ï¸ Manual Control

```bash
# Start service
bash scripts/start.sh

# Stop service
bash scripts/stop.sh

# Check status
launchctl list | grep videochat
```

## ğŸ“„ License

MIT License â€” see [LICENSE](./LICENSE).

## ğŸ™ Credits

- [OpenClaw](https://github.com/openclaw/openclaw) â€” AI agent framework
- [Groq](https://groq.com) â€” Ultra-fast Whisper inference
- [edge-tts](https://github.com/rany2/edge-tts) â€” Free Microsoft TTS
- [mkcert](https://github.com/FiloSottile/mkcert) â€” Local HTTPS certificates
